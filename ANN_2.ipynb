{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Neural:\n",
    "    \n",
    "    def __init__(self, inputlayer, hiddenlayer1, hiddenlayer2, outputlayer, learningrate):\n",
    "        self.inode = inputlayer\n",
    "        self.hnode_1 = hiddenlayer1\n",
    "        self.hnode_2 = hiddenlayer2\n",
    "        self.onode   = outputlayer\n",
    "        \n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # random initialization of weights\n",
    "        \n",
    "        self.w_h1 = np.random.normal(0.0, pow(self.hnode_1, -0.5), (self.hnode_1, self.inode))\n",
    "        self.w_h2 = np.random.normal(0.0, pow(self.hnode_2, -0.5), (self.hnode_2, self.hnode_1))\n",
    "        self.who  = np.random.normal(0.0, pow(self.onode, -0.5), (self.onode, self.hnode_2))\n",
    "        \n",
    "        # random initialization of bias\n",
    "        \n",
    "        self.b_h1 = np.random.normal(0.0, 1, (self.hnode_1,1))\n",
    "        self.b_h2 = np.random.normal(0.0, 1, (self.hnode_2,1))\n",
    "        self.bho  = np.random.normal(0.0, 1, (self.onode,1))\n",
    "        \n",
    "        self.sigmoid = lambda x: 1/(1 + np.exp(-x))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    \n",
    "    def train(self, input_data, target_data):\n",
    "        # first calculate the output\n",
    "        input_data = np.array(input_data, ndmin = 2).T\n",
    "        target_data = np.array(target_data, ndmin = 2).T\n",
    "        \n",
    "        # squashing of first layer\n",
    "        self.z_h1 = np.dot(self.w_h1, input_data) + self.b_h1\n",
    "        self.hidden_output_1 = self.sigmoid(self.z_h1)\n",
    "        \n",
    "        # squashing of second layer\n",
    "        self.z_h2 = np.dot(self.w_h2, self.hidden_output_1) + self.b_h2\n",
    "        self.hidden_output_2 = self.sigmoid(self.z_h2)\n",
    "        \n",
    "        # delivery of output\n",
    "        self.z_o = np.dot(self.who, self.hidden_output_2) + self.bho\n",
    "        self.final_output = self.sigmoid(self.z_o)\n",
    "        \n",
    "        # backpropagation\n",
    "        \n",
    "        # Calculation of errors\n",
    "        \n",
    "        output_error = target_data - self.final_output\n",
    "        hidden_error_layer_2 = np.dot(self.who.T, output_error)\n",
    "        hidden_error_layer_1 = np.dot(self.w_h2.T, hidden_error_layer_2)\n",
    "        \n",
    "        # Gradient Descent\n",
    "        \n",
    "        self.who = self.who + self.lr*np.dot(output_error*self.final_output*(1- self.final_output), self.hidden_output_2.T)\n",
    "        self.w_h2 = self.w_h2 + self.lr*np.dot(hidden_error_layer_2*self.hidden_output_2*(1-self.hidden_output_2), self.hidden_output_1.T)\n",
    "        self.w_h1 = self.w_h1 + self.lr*np.dot(hidden_error_layer_1*self.hidden_output_1*(1-self.hidden_output_1), input_data.T)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def ans(self, input_data):\n",
    "        \n",
    "        input_data = np.array(input_data, ndmin = 2).T\n",
    "        \n",
    "        # squashing of first layer\n",
    "        self.z_h1 = np.dot(self.w_h1, input_data) + self.b_h1\n",
    "        self.hidden_output_1 = self.sigmoid(self.z_h1)\n",
    "        \n",
    "        # squashing of second layer\n",
    "        self.z_h2 = np.dot(self.w_h2, self.hidden_output_1) + self.b_h2\n",
    "        self.hidden_output_2 = self.sigmoid(self.z_h2)\n",
    "        \n",
    "        # delivery of output\n",
    "        self.z_o = np.dot(self.who, self.hidden_output_2) + self.bho\n",
    "        self.final_output = self.sigmoid(self.z_o)\n",
    "        \n",
    "        return self.final_output\n",
    "    pass\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputlayer = 784\n",
    "hiddenlayer1 = 500\n",
    "hiddenlayer2 = 500\n",
    "outputlayer  = 10\n",
    "learningrate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ANN = Neural(inputlayer, hiddenlayer1, hiddenlayer2, outputlayer, learningrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_file = open('C:\\\\Users\\\\kunal\\\\Downloads\\\\mnist_train.csv', 'r')\n",
    "data_file = open('F:\\\\machine learning\\\\urgent study\\\\mnist_train_100.csv', 'r')\n",
    "data_line = data_file.readlines()\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kunal\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:24: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "for every_line in data_line:\n",
    "    inputs = every_line.split(',')\n",
    "    inputs_net = np.asfarray(inputs[1:])\n",
    "    target = np.zeros(outputlayer) \n",
    "    target[int(inputs[0])] = 1\n",
    "    ANN.train(inputs_net, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kunal\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:24: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.9\n"
     ]
    }
   ],
   "source": [
    "data_test_file = open('C:\\\\Users\\\\kunal\\\\Downloads\\\\mnist_test.csv','r')\n",
    "data_test_line = data_test_file.readlines()\n",
    "data_test_file.close()\n",
    "\n",
    "score = []\n",
    "for test in data_test_line:\n",
    "    test_data = test.split(',')\n",
    "    correct_ans = float(test_data[0])\n",
    "    test_data = np.asfarray(test_data[1:])\n",
    "    Neural = ANN.ans(test_data)\n",
    "    Neural = float(Neural.argmax())\n",
    "#    print('The correct ans is: ', correct_ans)\n",
    "#    print('The answer predicted is: ', Neural)\n",
    "#    print()\n",
    "    if correct_ans == Neural:\n",
    "        score.append(1)\n",
    "    else:\n",
    "        score.append(0)\n",
    "percentage_score = (sum(score)/len(score))*100\n",
    "\n",
    "print(percentage_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([2,3,4], ndmin =4)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
